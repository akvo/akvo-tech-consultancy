{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Global-Configurations\" data-toc-modified-id=\"Global-Configurations-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Global Configurations</a></span></li><li><span><a href=\"#Filter-Columns-&amp;-Rows\" data-toc-modified-id=\"Filter-Columns-&amp;-Rows-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Filter Columns &amp; Rows</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ignore-Suffix\" data-toc-modified-id=\"Ignore-Suffix-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Ignore Suffix</a></span></li><li><span><a href=\"#Fill-Empty-Integer-Values\" data-toc-modified-id=\"Fill-Empty-Integer-Values-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Fill Empty Integer Values</a></span></li><li><span><a href=\"#Replace-Empty-String-Values\" data-toc-modified-id=\"Replace-Empty-String-Values-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Replace Empty String Values</a></span></li><li><span><a href=\"#Get-Time-Series-Values\" data-toc-modified-id=\"Get-Time-Series-Values-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Get Time Series Values</a></span></li><li><span><a href=\"#Get-LatLong-Values\" data-toc-modified-id=\"Get-LatLong-Values-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Get LatLong Values</a></span></li><li><span><a href=\"#Replace-Akvo-Flow-Column-Names\" data-toc-modified-id=\"Replace-Akvo-Flow-Column-Names-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Replace Akvo Flow Column Names</a></span></li><li><span><a href=\"#Replace-Datetime-to-String\" data-toc-modified-id=\"Replace-Datetime-to-String-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Replace Datetime to String</a></span></li></ul></li><li><span><a href=\"#Generate-Settings\" data-toc-modified-id=\"Generate-Settings-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Generate Settings</a></span><ul class=\"toc-item\"><li><span><a href=\"#JSON-Config\" data-toc-modified-id=\"JSON-Config-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>JSON Config</a></span></li><li><span><a href=\"#Replace-Dataset-Columns\" data-toc-modified-id=\"Replace-Dataset-Columns-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Replace Dataset Columns</a></span></li><li><span><a href=\"#Define-Categories\" data-toc-modified-id=\"Define-Categories-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Define Categories</a></span></li><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Overview</a></span></li></ul></li><li><span><a href=\"#Record-Data\" data-toc-modified-id=\"Record-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Record Data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T04:14:31.405923Z",
     "start_time": "2020-05-29T04:14:30.422263Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import sqlalchemy as db\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import requests as r\n",
    "from datetime import datetime\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "pd.set_option('max_columns', 200)\n",
    "\n",
    "# class\n",
    "from handler import handler\n",
    "\n",
    "#import json\n",
    "#import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(endpoint):\n",
    "    data = r.get(endpoint, headers=headers)\n",
    "    if(data.status_code == 200):\n",
    "        return data.json()\n",
    "    return data.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectData(url, collections=[]):\n",
    "    fetch = getData(url)\n",
    "    data = fetch.get(\"formInstances\")\n",
    "    if len(data) != 0:\n",
    "        for d in data:\n",
    "            collections.append(d)\n",
    "        next_page = fetch.get(\"nextPageUrl\")\n",
    "        collectData(next_page, collections)\n",
    "    return collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, qgroups, dataPointId):\n",
    "    answers = {\"data_point_id\": dataPointId}\n",
    "    for qgroup in qgroups:\n",
    "        gid = qgroup['id']\n",
    "        questions = qgroup.get('questions')\n",
    "        for index, question in enumerate(questions):\n",
    "            qid = question['id']\n",
    "            qname = question['name'].strip() # remove whitespace on start end\n",
    "            qtype = question['type']\n",
    "            key = '{}|{}'.format(qid, qname)\n",
    "            try:\n",
    "                answer = data[gid][0][qid]\n",
    "                answer = handler(answer,qtype)\n",
    "                answers.update({key:answer})\n",
    "            except:\n",
    "                answers.update({key:None})\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toList(datas):\n",
    "    res = []\n",
    "    for data in datas:\n",
    "        res.append(data)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchCascade(sqlite, parent, collect, level=0):\n",
    "    # parent = 0 if level 1\n",
    "    cascadeURL = 'http://tech-consultancy.akvo.org/akvo-flow-web-api/cascade/{}/{}/{}'.format(instance, sqlite, parent)\n",
    "    data = r.get(cascadeURL).json()\n",
    "    if len(data) > 0:\n",
    "        for x in data:\n",
    "            x['level'] = level\n",
    "            collect.append(x)\n",
    "            nextLevel = level + 1\n",
    "            fetchCascade(sqlite, x.get('id'), collect, nextLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuestionVal(q, secondary_filter, result):\n",
    "    for x in secondary_filter:\n",
    "        if x.get('question_id') == int(q.get('id')):\n",
    "            tmp = x\n",
    "    if (q.get('type') == 'cascade'):\n",
    "        cascades = []\n",
    "        sqlite = q.get('cascadeResource')\n",
    "        fetchCascade(sqlite, 0, cascades)  \n",
    "        tmp['values'] = cascades\n",
    "    \n",
    "    if (q.get('type') == 'option'):\n",
    "        options = q.get('options').get('option')\n",
    "        tmp['values'] = options\n",
    "        \n",
    "    result.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakQuestion(qg, secondary_filter, result):\n",
    "    second_cat_id = [int(item.get('question_id')) for item in secondary_filter]\n",
    "    if (isinstance(qg.get('question'), list)):\n",
    "        for q in qg.get('question'):\n",
    "            if(int(q.get('id')) in second_cat_id):\n",
    "                getQuestionVal(q, secondary_filter, result)\n",
    "    else:\n",
    "        if(int(qg.get('question').get('id')) in second_cat_id):\n",
    "            getQuestionVal(q, secondary_filter, result)\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineSecondaryFilter(secondary_filter, flowAPI):\n",
    "    result = []\n",
    "    flowData = r.get(flowAPI).json()\n",
    "    if (isinstance(flowData.get('questionGroup'), list)):\n",
    "        for qg in flowData.get('questionGroup'):\n",
    "            breakQuestion(qg, secondary_filter, result)\n",
    "    else:\n",
    "        breakQuestion(flowData.get('questionGroup').get('question'), secondary_filter, result)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(data):\n",
    "    insert_stmt = insert(data_sources).values(\n",
    "            id = data.get('id'),\n",
    "            parent_id = data.get('parent_id'),\n",
    "            type = data.get('type'),\n",
    "            source = data.get('source'),\n",
    "            config = data.get('config'),\n",
    "            categories = data.get('categories'),\n",
    "            second_categories = data.get('second_categories'),\n",
    "            data = data.get('data'),\n",
    "            css = data.get('css'),\n",
    "            js = data.get('js')\n",
    "    )\n",
    "\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(\n",
    "                parent_id = insert_stmt.inserted.parent_id,\n",
    "                type = insert_stmt.inserted.type,\n",
    "                source = insert_stmt.inserted.source,\n",
    "                config = insert_stmt.inserted.config,\n",
    "                categories = insert_stmt.inserted.categories,\n",
    "                second_categories = insert_stmt.inserted.second_categories,\n",
    "                data = insert_stmt.inserted.data,\n",
    "                css = insert_stmt.inserted.css,\n",
    "                js = insert_stmt.inserted.js\n",
    "    )\n",
    "\n",
    "    connection.execute(on_duplicate_key_stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auth0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = {\n",
    "    \"client_id\": os.environ[\"AUTH0_CLIENT_ID_PROD\"],\n",
    "    \"username\": os.environ[\"AUTH0_USER_PROD\"],\n",
    "    \"password\": os.environ[\"AUTH0_PWD_PROD\"],\n",
    "    \"grant_type\":\"password\",\n",
    "    \"scope\":\"openid email\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = r.post(\"https://akvo.eu.auth0.com/oauth/token\", data=auth).json()[\"id_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\":\"application/json\",\n",
    "    \"Accept\": \"application/vnd.akvo.flow.v2+json\",\n",
    "    \"Authorization\": \"Bearer {}\".format(token)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'http://localhost:8000'\n",
    "host = 'http://akvo-map.localhost'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Connection to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine('mysql+pymysql://phpmyadmin:'+os.environ['SQL_PWD']+'@localhost/akvo-map?host=localhost?port=3306')\n",
    "connection = engine.connect()\n",
    "metadata = db.MetaData(bind=engine)\n",
    "data_sources = db.Table('data_sources', metadata, autoload=True, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Config\n",
    "##### Get from api/surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyURL = '{}/api/surveys'.format(host)\n",
    "surveyConfig = r.get(surveyURL).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in surveyConfig:\n",
    "    ## Global Configurations ======================================================\n",
    "    survey_id = x\n",
    "    apiURL = '{}/api/custom/{}'.format(host, survey_id)\n",
    "    php_config = r.get(apiURL).json()\n",
    "    \n",
    "    instance = php_config['survey_detail']['instance']\n",
    "    geo = php_config['survey_detail']['geolocation']\n",
    "    center_map =  php_config['survey_detail']['center_map'] # array integer\n",
    "    sources = php_config['sources'];\n",
    "    url = \"https://api-auth0.akvo.org/flow/orgs/{}\".format(instance)\n",
    "    \n",
    "    akvoflow = True # boolean\n",
    "    max_category = 10 # integer\n",
    "    ignore_suffix = '' # integer\n",
    "    empty_string_value = 'No Answer' # String\n",
    "    timeseries = '' # String\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Get, Transform and Insert Data ======================================================\n",
    "    ### Get Data from Flow Api\n",
    "    surveys = getData(\"{}/surveys/{}\".format(url, survey_id))\n",
    "    dataPoints = getData('{}/data_points?survey_id={}'.format(url, survey_id))\n",
    "    forms = surveys.get('forms')\n",
    "\n",
    "    ### Transform and Insert Data\n",
    "    for source in sources:\n",
    "        print(\"Start\")\n",
    "        print(\"{} - {} : {}\".format(source.get('id'), source.get('name'), source.get('type')))\n",
    "\n",
    "        # Check type of source\n",
    "        if (source.get('type') == 'survey'):\n",
    "            # Survey Details\n",
    "            data = {\n",
    "                \"id\" : source.get('id'),\n",
    "                \"parent_id\" : source.get('parent_id'),\n",
    "                \"type\" : source.get('type'),\n",
    "                \"source\" : source.get('name')\n",
    "            }\n",
    "            query(data)\n",
    "\n",
    "        else:\n",
    "            # Get Form Details from Flow\n",
    "            for form in forms:\n",
    "                if (int(form.get('id')) == source.get('id')):\n",
    "                    formInstanceURL = form.get('formInstancesUrl')\n",
    "                    qgroups = form.get('questionGroups')\n",
    "                    qtype = \"\"\n",
    "                    for qgroup in qgroups:\n",
    "                        questions = qgroup.get('questions')\n",
    "                        for question in questions:\n",
    "                            # check registration form\n",
    "                            if (source.get('type') == 'registration'):\n",
    "                                # set geo type\n",
    "                                if (question.get('type') == 'GEO'):\n",
    "                                    qtype = 'GEO'\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "            print(\"Akvo Flow API\")\n",
    "            start_time = datetime.now() # time start\n",
    "            print(\"Collecting Data\")\n",
    "            rowData = collectData(formInstanceURL)\n",
    "            end_time = datetime.now() # time end\n",
    "            print('Duration to collect data: {}'.format(end_time - start_time))\n",
    "\n",
    "            df = pd.DataFrame()\n",
    "            df = df.iloc[0:0]\n",
    "            df = pd.DataFrame(rowData)\n",
    "            df['responses'] = df[['responses', 'dataPointId']].apply(lambda x : transform(x['responses'], qgroups, x['dataPointId']), axis=1)\n",
    "            responses = toList(df['responses'])\n",
    "            results = pd.DataFrame(responses)\n",
    "\n",
    "            # cek if geo not exists\n",
    "            if (geo not in results.columns and source.get('type') == 'registration' ):\n",
    "                print('No geolocation in this survey!')\n",
    "                pass\n",
    "            else:\n",
    "                if (qtype == 'GEO'):\n",
    "                    ##### Split geo-loc column into separate column\n",
    "                    point = pd.Series(results[geo].values.flatten())\n",
    "                    loc = point.str.split(\",\", n = 1, expand = True)\n",
    "                    # create separate first name column from new data frame \n",
    "                    results[\"lat\"]= loc[0] \n",
    "                    # create separate last name column from new data frame \n",
    "                    results[\"long\"]= loc[1] \n",
    "                    # Dropping old Name columns \n",
    "                    results.drop(columns = geo, inplace = True) \n",
    "\n",
    "                res = results.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "                if (qtype == 'GEO'):\n",
    "                    res = res.dropna(subset=['lat', 'long'])\n",
    "\n",
    "                if (source.get('type') == 'monitoring'):\n",
    "                    res = res.dropna().reset_index(drop=True)\n",
    "\n",
    "                ##### Save file\n",
    "                output_filename = '{}.xlsx'.format(source.get('id'))\n",
    "                res.to_excel(output_filename, index=False)\n",
    "\n",
    "                # df = res\n",
    "                dataset = output_filename # string\n",
    "                try:\n",
    "                    df = pd.read_excel(dataset)\n",
    "                except:\n",
    "                    df = pd.read_csv(dataset)\n",
    "\n",
    "\n",
    "                ## Filter Columns & Rows ======================================================\n",
    "                print(\"Filter Columns & Rows\")\n",
    "                ### Ignore Suffix\n",
    "                if ignore_suffix:\n",
    "                    df = df[[c for c in df.columns if ignore_suffix not in c]]\n",
    "\n",
    "                ### Fill Empty Integer Values\n",
    "                numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "                if (qtype == 'GEO'):\n",
    "                    # Redeclare lat_long\n",
    "                    lat_long = ['long', 'lat'] # Array String # default, do not change\n",
    "                    df_num = df.select_dtypes(include=numerics).drop(columns=lat_long).drop(columns='data_point_id')\n",
    "                else:\n",
    "                    df_num = df.select_dtypes(include=numerics).drop(columns='data_point_id')\n",
    "\n",
    "                df_num = df_num.fillna(0.0).astype(np.int32)\n",
    "                df[list(df_num)] = df_num\n",
    "\n",
    "                ### Replace Empty String Values\n",
    "                df_str = df.select_dtypes(include=['object']).fillna(empty_string_value)\n",
    "                df[list(df_str)] = df_str\n",
    "\n",
    "                ### Get Time Series Values\n",
    "                if timeseries:\n",
    "                    df[timeseries] = df[timeseries].apply(lambda x:x.replace(' UTC','').replace(' UTC',''))\n",
    "                    df[timeseries] = pd.to_datetime(df[timeseries], format='%d-%m-%Y %H:%M:%S')\n",
    "                    df['TMS'] = df[timeseries]\n",
    "                    df = df.drop(columns=[timeseries])\n",
    "                    not_category.append('TMS')\n",
    "\n",
    "                ### Get LatLong Values\n",
    "                if (qtype == 'GEO'):\n",
    "                    df[lat_long] = df[lat_long].round({lat_long[0]: 3, lat_long[1]: 3})\n",
    "                    df['PTS'] = df[lat_long].values.tolist()\n",
    "                    df = df.drop(columns=lat_long)\n",
    "\n",
    "                ### Replace Akvo Flow Column Names\n",
    "                rep_indicators = [(lambda x: x.lower().replace('GEOLON',''))(x) for x in list(df)]\n",
    "                header = lambda a: [x.lower() if x.find(\"|\") == -1 else x.split('|')[1].lower().replace(\"--other--\",\" other\") for x in a]\n",
    "                headerIds = lambda a: [x.split('|')[0] for x in a]\n",
    "                column_names = list(df)\n",
    "                column_ids = headerIds(list(df))\n",
    "                if akvoflow:\n",
    "                    column_names = header(list(df))\n",
    "                    column_ids = headerIds(list(df))\n",
    "\n",
    "                ### Replace Datetime to String\n",
    "                for c in list(df):\n",
    "                    if 'time' in str(df[c].dtype):\n",
    "                        df[c] = df[c].astype('str')\n",
    "\n",
    "\n",
    "\n",
    "                ## Generate Settings ======================================================\n",
    "                print(\"Generate Settings\")\n",
    "                ### JSON Config\n",
    "                chars =list(string.ascii_uppercase)\n",
    "                chars_col = chars + [x+y for x in chars for y in chars]\n",
    "                keyname = lambda x,y: {a:y[b] if (a != 'data_point_id') else 'data_point_id' for b, a in enumerate(x)}\n",
    "\n",
    "                columns_length = len(list(df)) - 1 # -1 because of datapointid\n",
    "                if (qtype == 'GEO'):\n",
    "                    columns_length = len(list(df)) - 2 # -2 because of datapointid\n",
    "\n",
    "                index = chars_col[:columns_length]\n",
    "                index.append('data_point_id') # append 'data_point_id'\n",
    "                configs = keyname(index, column_names)\n",
    "                config_ids = keyname(index, column_ids)\n",
    "\n",
    "                if (qtype == 'GEO'):\n",
    "                    index.append('PTS')\n",
    "\n",
    "                ### Replace Dataset Columns\n",
    "                df.columns = index\n",
    "\n",
    "                ### Define Categories & Second Categories \n",
    "                categories_config = source.get('list') # array from config\n",
    "                secondary_filter = source.get('secondary_filter')\n",
    "                sfVal = None\n",
    "                if (len(secondary_filter) > 0):\n",
    "                    print('Generate Secondary Filter Data')\n",
    "                    flowAPI = 'http://tech-consultancy.akvo.org/akvo-flow-web-api/{}/{}/fetch'.format(instance, source.get('id'))\n",
    "                    sfVal = defineSecondaryFilter(secondary_filter, flowAPI)\n",
    "                    for sf in sfVal:\n",
    "                        for key in config_ids:\n",
    "                            if(config_ids[key] == str(sf.get('question_id'))):\n",
    "                                del sf['question_id']\n",
    "                                del sf['question_text']\n",
    "                                sf['id'] = key\n",
    "                    \n",
    "                \n",
    "                questionIds = [item.get('question_id') for item in categories_config]\n",
    "                categories = []\n",
    "                columns = list(df.columns)\n",
    "                if (qtype == 'GEO'):\n",
    "                    columns = list(df.drop(columns=['PTS']).columns)\n",
    "                    \n",
    "                #### Define Categories & Second Categories\n",
    "                for column in columns:\n",
    "                    x = column\n",
    "                    category = df.groupby(df[x]).size()\n",
    "                    category_name = configs[x]\n",
    "                    category_id = config_ids[x]\n",
    "                    data_type = str(df[x].dtype)\n",
    "\n",
    "                    if(category_id == 'data_point_id'):\n",
    "                        category_id = 0\n",
    "\n",
    "                    if(not int(category_id) in questionIds):\n",
    "                        pass\n",
    "                    else:\n",
    "                        type = [item.get('type') for item in categories_config if item.get('question_id') == int(category_id)][0]\n",
    "                        if (type == 'option'):\n",
    "                            type = 'list'\n",
    "                        if (type == 'number'):\n",
    "                            type = 'num'\n",
    "                        if len(category) <= max_category and data_type == 'object':\n",
    "                            category_list = list(category.index)\n",
    "                            categories.append({\n",
    "                                'id':x,\n",
    "                                'type': type,\n",
    "                                'lookup': category_list,\n",
    "                                'name': category_name,\n",
    "                                'question_id': category_id,\n",
    "                            })\n",
    "                        elif data_type == 'int32':\n",
    "                            categories.append({\n",
    "                                'id':x,\n",
    "                                'type': type,\n",
    "                                'name': category_name,\n",
    "                                'question_id': category_id,\n",
    "                            })\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                        \n",
    "                ### Overview\n",
    "                cat = pd.DataFrame(categories)\n",
    "                selected_cat = source.get('selected_category').lower() # string from config\n",
    "                popup_name = source.get('popup_name') # string from config\n",
    "                first_cat = cat[(cat['type'] == 'list') & (cat['name'] == selected_cat)].reset_index().loc[0].to_dict()['id']\n",
    "                conf_series = pd.Series(configs).to_frame('name')\n",
    "                popup_name = conf_series[conf_series['name'] == popup_name.lower()].index.tolist()[0]\n",
    "                # Search config\n",
    "                search_conf = [x.lower() for x in source.get('search')]\n",
    "                searchs = []\n",
    "                for x in search_conf:\n",
    "                    tmp = conf_series[conf_series['name'] == x].index.tolist()[0]\n",
    "                    searchs.append(tmp)\n",
    "                configs.update({'center':center_map,'name':first_cat,'popup':popup_name, 'search': searchs})\n",
    "\n",
    "\n",
    "\n",
    "                ## Record Data ======================================================\n",
    "                print(\"Record Data\")\n",
    "                data = list(df.T.to_dict().values())\n",
    "                templates = source.get('template')\n",
    "                css = [item.get('css') for item in templates]\n",
    "                js = [item.get('js') for item in templates]\n",
    "\n",
    "                # encode data to base64\n",
    "                #json_encoded_list = json.dumps(data)\n",
    "                #b64_encoded_list = base64.b64encode(json_encoded_list.encode(\"utf-8\"))\n",
    "\n",
    "                db = {\n",
    "                    \"id\": source.get('id'),\n",
    "                    \"parent_id\": source.get('parent_id'),\n",
    "                    \"type\": source.get('type'),\n",
    "                    \"source\": source.get('name'),\n",
    "                    \"config\": configs,\n",
    "                    \"categories\": categories,\n",
    "                    \"second_categories\": sfVal,\n",
    "                    \"data\": data,\n",
    "                    \"css\": css,\n",
    "                    \"js\": js\n",
    "                }\n",
    "\n",
    "                query(db)\n",
    "                os.remove(output_filename)\n",
    "\n",
    "            print(\"End\")\n",
    "\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Close Connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding\n",
    "#b64_encoded_list = base64.b64encode(json_encoded_list.encode(\"utf-8\"))\n",
    "#decoded_list = base64.b64decode(b64_encoded_list).decode(\"utf-8\")\n",
    "#json.loads(decoded_list)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
